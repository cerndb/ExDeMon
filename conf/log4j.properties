# Set everything to be logged to the console
log4j.rootCategory=INFO, console, http

log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=/root/exdemon/log/spark-job.log
log4j.appender.file.MaxFileSize=10MB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.appender.http=ch.cern.log4j.HTTPAppender
log4j.appender.http.url=http://monit-logs.cern.ch:10012/
log4j.appender.http.add= producer="tape" type="exdemon-spark" environment="<environment>"

# There are monitors looking at these lines
log4j.logger.org.apache.spark.streaming.scheduler.JobScheduler=INFO, console, http
log4j.logger.org.apache.spark.scheduler.TaskSetManager=INFO, console, http

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.apache.hadoop.yarn.server.webproxy=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.spark.streaming.kafka010.CachedKafkaConsumer=INFO